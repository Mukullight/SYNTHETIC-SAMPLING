{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56a76d86",
   "metadata": {},
   "source": [
    "## Decision Tree Algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dfb00d",
   "metadata": {},
   "source": [
    "# Decision Tree Algorithm\n",
    "\n",
    "## Input and Notation\n",
    "\n",
    "- $D$: The dataset, consisting of a set of instances and their associated attributes.\n",
    "- $A$: The set of candidate attributes.\n",
    "- $C$: The set of classes or labels.\n",
    "- $X$: The feature space, i.e., the space of possible attribute vectors.\n",
    "- $Y$: The set of possible class labels.\n",
    "- $\\text{Split}(D, A)$: A function to split the dataset $D$ based on the attribute that maximizes information gain.\n",
    "- $\\text{CreateNode}(A_i)$: A function to create a tree node for the selected attribute $A_i$.\n",
    "- $\\text{IsPure}(D)$: A function to check if the dataset $D$ is pure (contains only one class).\n",
    "- $T$: The decision tree model, represented as a tree structure.\n",
    "\n",
    "## Decision Tree Learning\n",
    "\n",
    "1. **Selecting the Best Attribute**:\n",
    "\n",
    "   - We start by selecting the attribute that provides the most information, often measured by information gain or Gini impurity. The chosen attribute becomes the root of the decision tree.\n",
    "   \n",
    "   $$\n",
    "   A^* = \\arg \\max_{A \\in A} \\text{InformationGain}(D, A)\n",
    "   $$\n",
    "\n",
    "2. **Creating Tree Nodes**:\n",
    "\n",
    "   - For each attribute $A_i$, we create a tree node and label it with the chosen attribute.\n",
    "\n",
    "   $$\n",
    "   \\text{TreeNode}(A_i) = \\text{CreateNode}(A_i)\n",
    "   $$\n",
    "\n",
    "3. **Splitting the Dataset**:\n",
    "\n",
    "   - We divide the dataset into subsets based on the values of the selected attribute.\n",
    "   \n",
    "   $$\n",
    "   \\text{Subsets} = \\text{Split}(D, A^*)\n",
    "   $$\n",
    "\n",
    "4. **Repeat for Subsets**:\n",
    "\n",
    "   - For each subset, we recursively apply the decision tree algorithm.\n",
    "   \n",
    "   $$\n",
    "   \\text{TreeNode}(A_i) = \\text{DecisionTree}(A_i)\n",
    "   $$\n",
    "\n",
    "5. **Stop Conditions**:\n",
    "\n",
    "   - If a stopping condition is met, we create a leaf node with the majority class label. This might be due to conditions such as:\n",
    "     - The subset is pure (contains only one class).\n",
    "     - A predefined maximum depth is reached.\n",
    "     - A minimum number of instances in a node is reached.\n",
    "\n",
    "6. **Tree Pruning (Optional)**:\n",
    "\n",
    "   - After constructing the tree, we can apply pruning techniques to reduce overfitting.\n",
    "\n",
    "7. **Output**:\n",
    "\n",
    "   - The decision tree $T$ is now ready for making predictions.\n",
    "\n",
    "\n",
    "### Example:\n",
    "\n",
    "Suppose we have a dataset with attributes A, B, and C, and the goal is to classify data into classes X, Y, and Z.\n",
    "\n",
    "- Selecting the best attribute might lead to:\n",
    "    - Node 1: Attribute A\n",
    "        - Subset 1: Value 1 -> Class X\n",
    "        - Subset 2: Value 2\n",
    "            - Node 2: Attribute B\n",
    "                - Subset 3: Value 1 -> Class X\n",
    "                - Subset 4: Value 2 -> Class Y\n",
    "    - Subset 5: Value 3 -> Class Z\n",
    "\n",
    "This textual representation outlines the steps of the decision tree algorithm and provides an example. You can adapt it to your specific machine learning model and dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bf5035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
